{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YjNuFkl5zQED",
        "outputId": "f4c4db28-ef14-464f-825e-9207ec02ec9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsympy is a library that return the derivative of a function, which is essential for this labwork\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from sympy import symbols, diff, lambdify\n",
        "import random\n",
        "#import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"\n",
        "sympy is a library that return the derivative of a function, which is essential for this labwork\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementation of gradient descent from scratch. this iterative function will:\n",
        "1. Take the input f, learning rate r, iteration iters\n",
        "2. Initialize x0\n",
        "3. calculate the first derivative of f as f_deri\n",
        "4. return the new value of x0 = x0 - r * f_deri(x0), after looping through iters\n",
        "5. re-compute f(x), stop when f(x) is small enough\n",
        "\"\"\"\n",
        "\n",
        "def gradient_descent(f, r: float, iters: int =10):\n",
        "    x = symbols('x')\n",
        "    f_deri = diff(f, x)\n",
        "    f = lambdify(x, f, 'math')\n",
        "    f_deri = lambdify(x, f_deri, 'math')\n",
        "\n",
        "    x0 = random.uniform(-10,10)\n",
        "    print(f\"{'Step'} {'x'} {'f(x)'}\")\n",
        "\n",
        "    for i in range(iters):\n",
        "      x0 = x0 - r * f_deri(x0)\n",
        "      f_value = f(x0)\n",
        "      print(f\"{i} {x0} {f_value}\")\n",
        "    return x0, f_value\n",
        "\n",
        "f = x**2\n",
        "for lr in [0.1,0.001,0.0001]:\n",
        "  x_final, f_value_final = gradient_descent(f, r=lr)\n",
        "  print(f\"learning rate: {lr}, x_final: {x_final}, f_value_final: {f_value_final}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INXdvJVn1EEJ",
        "outputId": "65ee7cae-8e31-4339-eb02-e93da84ea2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step x f(x)\n",
            "0 3.2949621270033758 10.85677541838661\n",
            "1 2.6359697016027006 6.948336267767431\n",
            "2 2.1087757612821605 4.446935211371155\n",
            "3 1.6870206090257285 2.8460385352775397\n",
            "4 1.3496164872205827 1.8214646625776252\n",
            "5 1.0796931897764661 1.16573738404968\n",
            "6 0.8637545518211729 0.7460719257917953\n",
            "7 0.6910036414569383 0.47748603250674887\n",
            "8 0.5528029131655506 0.3055910608043193\n",
            "9 0.4422423305324405 0.19557827891476434\n",
            "learning rate: 0.1, x_final: 0.4422423305324405, f_value_final: 0.19557827891476434\n",
            "Step x f(x)\n",
            "0 9.60146182897379 92.18806925324071\n",
            "1 9.582258905315841 91.81968572850475\n",
            "2 9.56309438750521 91.45277426433364\n",
            "3 9.5439681987302 91.08732897837338\n",
            "4 9.52488026233274 90.72334401177581\n",
            "5 9.505830501808074 90.36081352910473\n",
            "6 9.486818840804458 89.99973171824244\n",
            "7 9.467845203122849 89.64009279029634\n",
            "8 9.448909512716604 89.28189097950633\n",
            "9 9.43001169369117 88.92512054315222\n",
            "learning rate: 0.001, x_final: 9.43001169369117, f_value_final: 88.92512054315222\n",
            "Step x f(x)\n",
            "0 -5.898459484459664 34.79182428981217\n",
            "1 -5.897279792562772 34.77790895176921\n",
            "2 -5.89610033660426 34.76399917930487\n",
            "3 -5.894921116536938 34.7500949701931\n",
            "4 -5.893742132313631 34.736196322208826\n",
            "5 -5.892563383887168 34.722303233127796\n",
            "6 -5.8913848712103905 34.70841570072667\n",
            "7 -5.890206594236148 34.69453372278301\n",
            "8 -5.889028552917301 34.68065729707524\n",
            "9 -5.887850747206717 34.666786421382696\n",
            "learning rate: 0.0001, x_final: -5.887850747206717, f_value_final: 34.666786421382696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKSuP6_U1zRD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}